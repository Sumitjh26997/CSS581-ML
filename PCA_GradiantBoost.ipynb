{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sumitjh26997/CSS581-ML/blob/main/PCA_GradiantBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i1V0FgidvAF"
      },
      "source": [
        "**Chapter 7 – Boosting**\n",
        "\n",
        "_This notebook covers information from chapter 7 of the textbook on Gradiant Boosting. For help on sample code see page 205._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT4jhpH1dvAz"
      },
      "source": [
        "Train a Gradiant Boosting regressor on the California housing dataset._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYRjf22KdvAz"
      },
      "source": [
        "Let's load the dataset using Scikit-Learn's `fetch_california_housing()` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WuohwsaQdvAz"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X = housing[\"data\"]\n",
        "y = housing[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZLMt97gX012",
        "outputId": "92d93eba-a236-4a7f-ed7f-4709a07801f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk3TGTMudvAz"
      },
      "source": [
        "Split it into a training set and a test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SEv2Z-6bdvAz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tyxN2-8UdvAz"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Use GradientBoostingRegressor model in two settings 1) learning rate 1, number of estimators =3, and 2) learning rate 0.1 number of estimator =200 . What do you observe. Describe your observatioon in text format in canvas PCA."
      ],
      "metadata": {
        "id": "BtZu1zMEz-Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gbrt1 = GradientBoostingRegressor(n_estimators=3, learning_rate=1.0)\n",
        "gbrt1.fit(X_train_scaled, y_train)\n",
        "y_pred1 = gbrt1.predict(X_test_scaled)\n",
        "\n",
        "gbrt2 = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1)\n",
        "gbrt2.fit(X_train_scaled, y_train)\n",
        "y_pred2 = gbrt2.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "BRVO7uCsz8iN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, y_pred1))\n",
        "print(mean_squared_error(y_test, y_pred2))"
      ],
      "metadata": {
        "id": "A30hOFCXNZO3",
        "outputId": "c38e3247-3c62-4c9c-e736-1166ecf0962c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4473509371594874\n",
            "0.2614592448892024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is the good choice of values for these two hyper-parameters.\n",
        "Hint:\n",
        "\n",
        "In order to find the optimal number of trees, you can use early stopping. A simple way to implement this is to use the staged_predict() method: it returns an iterator over the predictions made by the ensemble at each stage of train‐ ing (with one tree, two trees, etc.).  See example code in book page 206."
      ],
      "metadata": {
        "id": "azn378G-2EKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "gbrt = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1)\n",
        "gbrt.fit(X_train_scaled, y_train)\n",
        "errors = [mean_squared_error(y_test, y_pred)\n",
        "for y_pred in gbrt.staged_predict(X_test_scaled)]\n",
        "bst_n_estimators = np.argmin(errors) + 1\n",
        "\n",
        "bst_n_estimators"
      ],
      "metadata": {
        "id": "kA6KT4ZA2BB8",
        "outputId": "79edfcf4-aeac-4207-9000-7f8f0addfe2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "991"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gbrt_best = GradientBoostingRegressor(n_estimators=bst_n_estimators, learning_rate=0.1)\n",
        "gbrt_best.fit(X_train_scaled, y_train)\n",
        "y_pred = gbrt_best.predict(X_test_scaled)\n",
        "print(mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "id": "1eA7d1WrTZgs",
        "outputId": "f218be3b-a48a-4787-f3c4-20359a6d0e81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.22319500733262296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gbrtw = GradientBoostingRegressor(warm_start=True)\n",
        "\n",
        "min_val_error = float(\"inf\")\n",
        "error_going_up = 0\n",
        "for n_estimators in range(1, 1000):\n",
        "  gbrtw.n_estimators = n_estimators\n",
        "  gbrtw.fit(X_train, y_train)\n",
        "  y_predw = gbrtw.predict(X_test)\n",
        "  val_error = mean_squared_error(y_test, y_predw)\n",
        "  if val_error < min_val_error:\n",
        "    min_val_error = val_error\n",
        "    error_going_up = 0\n",
        "  else:\n",
        "    error_going_up += 1\n",
        "    if error_going_up == 5:\n",
        "      break # early stopping"
      ],
      "metadata": {
        "id": "0U1t8TU_fRxr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators"
      ],
      "metadata": {
        "id": "aXxW42Yxf4K8",
        "outputId": "dcee61ec-9446-4792-a970-5c59712c6dcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "317"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gbrtw2 = GradientBoostingRegressor(warm_start=True)\n",
        "\n",
        "min_val_error = float(\"inf\")\n",
        "error_going_up = 0\n",
        "for n_estimators in range(1, 120):\n",
        "  gbrtw2.n_estimators = n_estimators\n",
        "  gbrtw2.fit(X_train_scaled, y_train)\n",
        "  y_predw = gbrtw2.predict(X_test)\n",
        "  val_error = mean_squared_error(y_test, y_predw)\n",
        "  if val_error < min_val_error:\n",
        "    min_val_error = val_error\n",
        "    error_going_up = 0\n",
        "  else:\n",
        "    error_going_up += 1\n",
        "    if error_going_up == 5:\n",
        "      break # early stopping"
      ],
      "metadata": {
        "id": "hrsUzgvtkEFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(y_test, y_predw)"
      ],
      "metadata": {
        "id": "PjhbicNigRhL",
        "outputId": "f9b8c662-3373-4ca8-ccac-2c69626f6c44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24746468738434815"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    'n_estimators': range(1, 200)\n",
        "}\n",
        "\n",
        "\n",
        "# Initialize the RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(GradientBoostingRegressor(), param_distributions=param_grid, n_iter=10, verbose=2, cv=3, random_state=42)\n",
        "\n",
        "# Fit the RandomizedSearchCV to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "print(\"Best parameters: \", best_params)\n",
        "\n"
      ],
      "metadata": {
        "id": "OoyXxVdcwgdP",
        "outputId": "040d8410-a9b0-4e78-c5e5-a0bbe84bf8bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] END ................learning_rate=0.6, n_estimators=132; total time=   5.7s\n",
            "[CV] END ................learning_rate=0.6, n_estimators=132; total time=   5.6s\n",
            "[CV] END ................learning_rate=0.6, n_estimators=132; total time=   3.9s\n",
            "[CV] END .................learning_rate=0.8, n_estimators=67; total time=   2.7s\n",
            "[CV] END .................learning_rate=0.8, n_estimators=67; total time=   1.9s\n",
            "[CV] END .................learning_rate=0.8, n_estimators=67; total time=   1.9s\n",
            "[CV] END .................learning_rate=0.5, n_estimators=65; total time=   1.8s\n",
            "[CV] END .................learning_rate=0.5, n_estimators=65; total time=   1.8s\n",
            "[CV] END .................learning_rate=0.5, n_estimators=65; total time=   1.8s\n",
            "[CV] END ................learning_rate=0.7, n_estimators=101; total time=   3.7s\n",
            "[CV] END ................learning_rate=0.7, n_estimators=101; total time=   2.9s\n",
            "[CV] END ................learning_rate=0.7, n_estimators=101; total time=   2.8s\n",
            "[CV] END ................learning_rate=0.6, n_estimators=136; total time=   3.8s\n",
            "[CV] END ................learning_rate=0.6, n_estimators=136; total time=   4.7s\n",
            "[CV] END ................learning_rate=0.6, n_estimators=136; total time=   4.6s\n",
            "[CV] END ................learning_rate=0.6, n_estimators=101; total time=   3.6s\n",
            "[CV] END ................learning_rate=0.6, n_estimators=101; total time=   3.7s\n",
            "[CV] END ................learning_rate=0.6, n_estimators=101; total time=   2.8s\n",
            "[CV] END ................learning_rate=0.9, n_estimators=133; total time=   3.8s\n",
            "[CV] END ................learning_rate=0.9, n_estimators=133; total time=   4.9s\n",
            "[CV] END ................learning_rate=0.9, n_estimators=133; total time=   4.3s\n",
            "[CV] END .................learning_rate=0.6, n_estimators=50; total time=   1.4s\n",
            "[CV] END .................learning_rate=0.6, n_estimators=50; total time=   1.4s\n",
            "[CV] END .................learning_rate=0.6, n_estimators=50; total time=   1.4s\n",
            "[CV] END .................learning_rate=0.9, n_estimators=47; total time=   1.3s\n",
            "[CV] END .................learning_rate=0.9, n_estimators=47; total time=   1.3s\n",
            "[CV] END .................learning_rate=0.9, n_estimators=47; total time=   1.6s\n",
            "[CV] END ................learning_rate=0.1, n_estimators=122; total time=   4.0s\n",
            "[CV] END ................learning_rate=0.1, n_estimators=122; total time=   3.4s\n",
            "[CV] END ................learning_rate=0.1, n_estimators=122; total time=   3.5s\n",
            "Best parameters:  {'n_estimators': 136, 'learning_rate': 0.6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_best = GradientBoostingRegressor(n_estimators= 136, learning_rate=0.6).fit(X_train_scaled, y_train).predict(X_test_scaled)\n",
        "mean_squared_error(y_test, y_pred_best)"
      ],
      "metadata": {
        "id": "1QBat6Mn0ROa",
        "outputId": "075f4f7d-00f2-44cd-a133-bd0f48863861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2496484627810789"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}